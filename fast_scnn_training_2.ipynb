{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fast_scnn_training_2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1-sDH7gI6Ihx_Jh7cxl22KGaPeQRViuXo","authorship_tag":"ABX9TyMwQoUXLTe+ja4BxR9K0Juf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7BHBUdTR91o","executionInfo":{"status":"ok","timestamp":1660474228886,"user_tz":-330,"elapsed":2555,"user":{"displayName":"Akhil Tony","userId":"09403758092042558153"}},"outputId":"e017c7e2-da35-4ae8-ad1e-1cf1553b5a79"},"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"]}],"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","import os\n","import numpy as np\n","import cv2 as cv\n","import keras.backend as K"]},{"cell_type":"markdown","source":["Model Building"],"metadata":{"id":"VOR2iDiBD3M-"}},{"cell_type":"code","source":["def conv_block(inputs,conv_type,kernel,kernel_size,strides,padding='same',relu=True):\n","    if conv_type == 'ds':\n","        x = tf.keras.layers.SeparableConv2D(kernel,kernel_size,padding=padding,strides=strides)(inputs)\n","    else:\n","        x = tf.keras.layers.Conv2D(kernel,kernel_size,padding=padding,strides=strides)(inputs)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    if relu:\n","        x = tf.keras.activations.relu(x)\n","    return x\n","\n","def _res_bottleneck(inputs,filters,kernel,t,s,r=False):\n","  tchannel = tf.keras.backend.int_shape(inputs)[-1]*t\n","  x = conv_block(inputs,'conv',tchannel,(1,1),strides=(1,1))\n","  x = tf.keras.layers.DepthwiseConv2D(kernel,strides=(s,s),depth_multiplier=1,padding='same')(x)\n","  x = tf.keras.layers.BatchNormalization()(x)\n","  x = tf.keras.activations.relu(x)\n","  x = conv_block(x,'conv',filters,(1,1),strides=(1,1),padding='same',relu=False)\n","  if r:\n","      x = tf.keras.layers.add([x,inputs])\n","  return x\n","\n","def bottleneck_block(inputs,filters,kernel,t,strides,n):\n","    x = _res_bottleneck(inputs,filters,kernel,t,strides)\n","    for i in range(1,n):\n","        x = _res_bottleneck(x,filters,kernel,t,1,True)\n","    return x\n","\n","def pyramid_pooling_block(input_tensor,bin_sizes):\n","    concat_list = [input_tensor]\n","#     w = 64\n","#     h = 32\n","    w = 32\n","    h = 64\n","    for bin_size in bin_sizes:\n","        x = tf.keras.layers.AveragePooling2D(pool_size=(w//bin_size,h//bin_size),strides=(w//bin_size,h//bin_size))(input_tensor)\n","        x = tf.keras.layers.Conv2D(128,3,2,padding='same')(x)\n","        x = tf.keras.layers.Lambda(lambda x:tf.image.resize(x,(w,h)))(x)\n","        concat_list.append(x)\n","    return tf.keras.layers.concatenate(concat_list)\n","\n","input_layer = tf.keras.layers.Input(shape=(512,1024,3),name='input_layer') #(2048,1024,3)\n","# input_layer = tf.keras.layers.BatchNormalization()(input_layer)\n","lds_layer = conv_block(input_layer,'conv',32,(3,3),strides=(2,2))\n","lds_layer = conv_block(lds_layer,'ds',48,(3,3),strides=(2,2))\n","lds_layer = conv_block(lds_layer,'ds',64,(3,3),strides=(1,1)) \n","gfe_layer = bottleneck_block(lds_layer,64,(3,3),t=6,strides=2,n=3) \n","gfe_layer = bottleneck_block(gfe_layer,96,(3,3),t=6,strides=2,n=3)\n","gfe_layer = bottleneck_block(gfe_layer,128,(3,3),t=6,strides=1,n=3) \n","gfe_layer = pyramid_pooling_block(gfe_layer,[2,4,6,8]) \n","ff_layer1 = conv_block(lds_layer,'conv',128,(1,1),padding='same',strides=(1,1),relu=False)\n","ff_layer2 = tf.keras.layers.UpSampling2D((4,4))(gfe_layer)\n","ff_layer2 = tf.keras.layers.DepthwiseConv2D(128,strides=(1,1),depth_multiplier=1,padding='same')(ff_layer2)\n","ff_layer2 = tf.keras.layers.BatchNormalization()(ff_layer2)\n","ff_layer2 = tf.keras.activations.relu(ff_layer2)\n","ff_layer2 = tf.keras.layers.Conv2D(128,1,1,padding='same',activation=None)(ff_layer2)\n","ff_final = tf.keras.layers.add([ff_layer1,ff_layer2])\n","ff_final = tf.keras.layers.BatchNormalization()(ff_final)\n","ff_final = tf.keras.activations.relu(ff_final)\n","classifier = tf.keras.layers.SeparableConv2D(128,(3,3),padding='same',strides=(1,1),name=\"DSConv1_classifier\")(ff_final)\n","classifier = tf.keras.layers.BatchNormalization()(classifier)\n","classifier = tf.keras.activations.relu(classifier)\n","\n","classifier = tf.keras.layers.SeparableConv2D(128,(3,3),padding='same',strides=(1,1),name=\"DSConv2_classifier\")(classifier)\n","classifier = tf.keras.layers.BatchNormalization()(classifier)\n","classifier = tf.keras.activations.relu(classifier)\n","\n","classifier = conv_block(classifier,'conv',9,(1,1),strides=(1,1),padding='same',relu=True) # classes number\n","\n","classifier = tf.keras.layers.Dropout(0.1)(classifier)\n","\n","classifier = tf.keras.layers.UpSampling2D((4,4))(classifier) #(8,8)\n","classifier = tf.keras.activations.softmax(classifier)"],"metadata":{"id":"XAKC7YZOSd69","executionInfo":{"status":"ok","timestamp":1660474230450,"user_tz":-330,"elapsed":1586,"user":{"displayName":"Akhil Tony","userId":"09403758092042558153"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Loss Function"],"metadata":{"id":"3KUKEIupJpHB"}},{"cell_type":"code","source":["# def dice_coef(y_true, y_pred, smooth=1):\n","#     y_true_f = K.flatten(y_true)\n","#     y_pred_f = K.flatten(y_pred)\n","#     intersection = K.sum(y_true_f * y_pred_f)\n","#     print(intersection)\n","#     return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","# def dice_coef_loss(y_true, y_pred):\n","#     return 1 - dice_coef(y_true, y_pred)\n","\n","def dice_coef(y_true, y_pred, smooth=1):\n","    \n","    y_true = y_true[...,1:]\n","    y_pred = y_pred[...,1:]\n","    \n","    numerator = 2 * K.sum(y_true * y_pred,axis=[0,1,2]) + smooth \n","    denominator = K.sum(y_true,axis=[0,1,2]) + K.sum(y_pred,axis=[0,1,2]) + smooth\n","    \n","    return K.mean( numerator / denominator )\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return 1 - dice_coef(y_true, y_pred)"],"metadata":{"id":"Ruoopr04GThd","executionInfo":{"status":"ok","timestamp":1660474230454,"user_tz":-330,"elapsed":30,"user":{"displayName":"Akhil Tony","userId":"09403758092042558153"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Compiling Model"],"metadata":{"id":"GciMeEoeGa5A"}},{"cell_type":"code","source":["fast_scnn = tf.keras.Model(inputs=input_layer, outputs=classifier, name = 'Fast_SCNN')\n","optimizer = tf.keras.optimizers.SGD(momentum=0.9,lr=0.32) \n","weights = '/content/drive/MyDrive/fast_scnn/checkpointweight0.h5'\n","fast_scnn.load_weights(weights)\n","\n","#metrics = tf.keras.metrics.MeanIoU(9, name=None, dtype=None)\n","fast_scnn.compile(loss=dice_coef_loss,optimizer=optimizer,metrics=[dice_coef])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8HFvCmCGX4s","executionInfo":{"status":"ok","timestamp":1660474230457,"user_tz":-330,"elapsed":28,"user":{"displayName":"Akhil Tony","userId":"09403758092042558153"}},"outputId":"d2c5cc77-9852-41d6-b29d-d17d2c577c20"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"markdown","source":["Data Pipeline"],"metadata":{"id":"4KTDe39ZDyqL"}},{"cell_type":"code","source":["image_path_og = os.path.join('drive','MyDrive','CITY','Resized','images')\n","label_path_og = os.path.join('drive','MyDrive','CITY','Resized','labels_limited')\n","file_order_path = os.path.join('drive','MyDrive','CITY','File Order')\n","  \n","def load_data(cat):\n","  x = []\n","  y = []\n","  \n","  img_order_path = os.path.join(file_order_path,'img_{}_file_order.npy'.format(cat))\n","  lab_order_path = os.path.join(file_order_path,'label_{}_file_order.npy'.format(cat))\n","  img_order = np.load(img_order_path)\n","  lab_order = np.load(lab_order_path)\n","  \n","  for img,lab in zip(img_order,lab_order):\n","    image_path = os.path.join(image_path_og,img)\n","    label_path = os.path.join(label_path_og,lab)\n","    m = img.split('leftImg8bit')\n","    l = lab.split('gtFine_labelIds')\n","    if m==l:\n","      x.append(image_path)\n","      y.append(label_path)\n","    else:\n","      print('[ERR]Data Mismatch')\n","  if cat == 'train':\n","    return x[720:],y[720:]\n","  else:\n","    return x,y\n","\n","def read_image(path):\n","  x = cv.imread(path)\n","  x = cv.cvtColor(x,cv.COLOR_BGR2RGB)\n","  return x\n","\n","def read_mask(path):\n","    x = cv.imread(path,cv.IMREAD_UNCHANGED)\n","    # x = np.expand_dims(x,2)\n","    x = (np.arange(9) == x[...,None]).astype(np.int8) #number_of_classes\n","    return x\n","\n","def preprocess(x, y):\n","  def f(x, y):\n","    x = x.decode()\n","    y = y.decode()\n","\n","    x = read_image(x)\n","    y = read_mask(y)\n","\n","    # return x, y\n","    return x, y.astype('float32')\n","\n","  images, masks = tf.numpy_function(f, [x, y], [tf.uint8, tf.float32])\n","  # images, masks = tf.numpy_function(f, [x, y], [tf.uint8, tf.float32])\n","  \n","  images.set_shape([512, 1024, 3])\n","  masks.set_shape([512, 1024, 9])\n","\n","  return images, masks\n","\n","def tf_dataset(x, y, batch=7):\n","  dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","  dataset = dataset.map(preprocess)\n","  dataset = dataset.batch(batch)\n","  dataset = dataset.prefetch(2)\n","  return dataset\n","\n","val_images, val_masks = load_data('val')\n","val_dataset = tf_dataset(val_images, val_masks)\n","\n","train_images, train_masks = load_data('train')\n","train_dataset = tf_dataset(train_images, train_masks)"],"metadata":{"id":"ZTIAJ2d8DnRj","executionInfo":{"status":"ok","timestamp":1660474231145,"user_tz":-330,"elapsed":709,"user":{"displayName":"Akhil Tony","userId":"09403758092042558153"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Training"],"metadata":{"id":"tXDmCiAADuGW"}},{"cell_type":"code","source":["filepath = os.path.join('drive','MyDrive','fast_scnn','checkpointweight0.h5')\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(\n","    filepath,\n","    monitor='accuracy',\n","    verbose=1,\n","    save_best_only=False,\n","    save_weights_only=True,\n","    save_freq=60,\n",")\n","H = fast_scnn.fit(train_dataset, epochs = 1, validation_data = (val_dataset),callbacks=[checkpoint])\n","fast_scnn.save_weights(os.path.join('drive','MyDrive','fast_scnn','weight_last.h5'))\n","model_path = os.path.join('drive','MyDrive','fast_scnn','fast_scnn.h5')\n","fast_scnn.save(model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HpSk1XiDDobd","outputId":"7bde9fb7-89a9-4dd7-81dc-3b6c13e4dead"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\r  1/323 [..............................] - ETA: 11:09:51 - loss: 0.5359 - dice_coef: 0.4641"]}]}]}